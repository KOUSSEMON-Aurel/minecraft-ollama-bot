*Image* : https://hub.docker.com/r/aurel126/minecraft-ollama-bot

ğŸ§  Minecraft + Local AI Bot (Dockerized)

This project provides a fully containerized environment that connects a Minecraft server with an AI-powered bot using Node.js, Ollama, and local LLM models.
It allows AI agents to join a live Minecraft world, chat with players, make decisions, explore, and perform real in-game actions â€” all without any manual setup.


âœ… Whatâ€™s Inside the Docker Image

âœ” Node.js AI Bot â€” runs the bot logic and connects to Minecraft
âœ” Ollama LLM Client â€” sends prompts to a local Ollama server for reasoning
âœ” Java (Temurin 21) & Python 3 â€” required for Minecraft and AI libraries
âœ” AWS CLI, Git, unzip, curl, system tools â€” preinstalled for automation
âœ” Minecraft server support (via external container)
âœ” Support for custom LLMs like sweaterdog/andy-4, embeddinggemma, etc.

You only need Docker & Docker Compose â€” no manual installation of Minecraft, Node.js, Java, or Python.


ğŸš€ Features

ğŸ¤– AI agents that chat, navigate, interact and perform actions in Minecraft

ğŸ§  Uses local LLM inference via Ollama (works completely offline)

ğŸ—ºï¸ Compatible with Vanilla Minecraft 1.20.2

ğŸ”„ Optional ViaProxy support for cross-version player compatibility

ğŸ“¦ Everything packaged inside Docker â€” easy to deploy on any machine or server

ğŸ’¾ Persistent volumes for saving Minecraft worlds and Ollama model data


ğŸ› ï¸ Full automation: pull â†’ compose up â†’ bot connects automatically

```
docker pull aurel126/minecraft-ollama-bot:latest
docker compose up -d
```


Example docker-compose.yml :

```
services:
  app:
    image: aurel126/minecraft-ollama-bot:latest
    environment:
      - OLLAMA_HOST=http://ollama:11434
    depends_on:
      ollama:
        condition: service_healthy
      minecraft:
        condition: service_healthy

  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    healthcheck:
      test: ["CMD", "ollama", "list"]
      interval: 10s
      retries: 5

  minecraft:
    image: itzg/minecraft-server
    environment:
      EULA: "TRUE"
      VERSION: "1.20.2"
    ports:
      - "25565:25565"
    volumes:
      - mc_data:/data
    healthcheck:
      test: ["CMD", "mc-health"]
      interval: 10s
      retries: 5

volumes:
  mc_data:
  ollama_data:

```


âš™ï¸ Included Inside the Image

| Component             | Version / Type            |
| --------------------- | ------------------------- |
| Node.js               | 22                        |
| Java                  | Temurin 21 (OpenJDK)      |
| Python                | 3.x + pip + boto3         |
| Minecraft Integration | Via mineflayer & RCON     |
| LLM Support           | Ollama API                |
| System Tools          | git, unzip, curl, AWS CLI |
| OS Base Image         | node:22 (Debian)          |


ğŸ›‘ Requirements

Docker & Docker Compose installed

At least 6 GB RAM recommended (Minecraft + LLM)

GPU optional (faster model inference with Ollama)

Linux, Windows or macOS supported
